{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03439b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "# Import tf_text to load the ops used by the tokenizer saved model\n",
    "import tensorflow_text  # pylint: disable=unused-import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3673466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                               as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd585531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'e quando melhoramos a procura , tiramos a \\xc3\\xbanica vantagem da impress\\xc3\\xa3o , que \\xc3\\xa9 a serendipidade .'\n",
      " b'mas e se estes fatores fossem ativos ?'\n",
      " b'mas eles n\\xc3\\xa3o tinham a curiosidade de me testar .'], shape=(3,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for pt_examples, en_examples in train_examples.batch(3).take(1):\n",
    "    print(pt_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1532168c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\ted_hrlr_translate_pt_en_converter.zip'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'ted_hrlr_translate_pt_en_converter'\n",
    "tf.keras.utils.get_file(\n",
    "    f'{model_name}.zip',\n",
    "    f'https://storage.googleapis.com/download.tensorflow.org/models/{model_name}.zip',\n",
    "    cache_dir='.', cache_subdir='', extract=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "917fb583",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizers = tf.saved_model.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cba62fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 72, 117, 79, 1259, 1491, 2362, 13, 79, 150, 184, 311, 71, 103, 2308, 74, 2679, 13, 148, 80, 55, 4840, 1434, 2423, 540, 15, 3]\n",
      "[2, 87, 90, 107, 76, 129, 1852, 30, 3]\n",
      "[2, 87, 83, 149, 50, 9, 56, 664, 85, 2512, 15, 3]\n"
     ]
    }
   ],
   "source": [
    "encoded = tokenizers.en.tokenize(en_examples)\n",
    "\n",
    "for row in encoded.to_list():\n",
    "  print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73582e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_TOKENS=500\n",
    "def filter_max_tokens(pt, en):\n",
    "  num_tokens = tf.maximum(tf.shape(pt)[1],tf.shape(en)[1])\n",
    "  return num_tokens < MAX_TOKENS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c02667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_pairs(pt, en):\n",
    "    pt = tokenizers.pt.tokenize(pt)\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    pt = pt.to_tensor()\n",
    "\n",
    "    en = tokenizers.en.tokenize(en)\n",
    "    # Convert from ragged to dense, padding with zeros.\n",
    "    en = en.to_tensor()\n",
    "    return pt, en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e13462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7eb3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batches(ds):\n",
    "  return (\n",
    "      ds\n",
    "      .cache()\n",
    "      .shuffle(BUFFER_SIZE)\n",
    "      .batch(BATCH_SIZE)\n",
    "      .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "      .filter(filter_max_tokens)\n",
    "      .prefetch(tf.data.AUTOTUNE))\n",
    "\n",
    "\n",
    "train_batches = make_batches(train_examples)\n",
    "val_batches = make_batches(val_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b6612fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76f08c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 4], dtype=int64),)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nonzero(np.array([1,2,3,0,4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3fe8fdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 0],\n",
       "       [1, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array([[1,2,3,0,4],[0,0,3,7,8]])\n",
    "np.where(a!=0,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7917bd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    npseq = seq.numpy()\n",
    "    \n",
    "    npmaskseq = np.where(npseq!=0,0,1)\n",
    "    tfseq = tf.convert_to_tensor(npmaskseq,dtype=tf.float32)\n",
    "    \n",
    "    tfseq = tfseq[:,tf.newaxis,tf.newaxis,:]\n",
    "    return tfseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71ea5439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_padding_mask(tf.constant([[7, 6, 0, 0, 1], [1, 2, 3, 0, 0], [0, 0, 0, 4, 5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff5049d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1*8*9*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0aa37e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(4608).reshape([64,8,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "384974af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 8, 64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1286dcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 8, 8), dtype=int32, numpy=\n",
       "array([[[      204,       528,       852, ...,      1824,      2148,\n",
       "              2472],\n",
       "        [      528,      1581,      2634, ...,      5793,      6846,\n",
       "              7899],\n",
       "        [      852,      2634,      4416, ...,      9762,     11544,\n",
       "             13326],\n",
       "        ...,\n",
       "        [     1824,      5793,      9762, ...,     21669,     25638,\n",
       "             29607],\n",
       "        [     2148,      6846,     11544, ...,     25638,     30336,\n",
       "             35034],\n",
       "        [     2472,      7899,     13326, ...,     29607,     35034,\n",
       "             40461]],\n",
       "\n",
       "       [[    52044,     58200,     64356, ...,     82824,     88980,\n",
       "             95136],\n",
       "        [    58200,     65085,     71970, ...,     92625,     99510,\n",
       "            106395],\n",
       "        [    64356,     71970,     79584, ...,    102426,    110040,\n",
       "            117654],\n",
       "        ...,\n",
       "        [    82824,     92625,    102426, ...,    131829,    141630,\n",
       "            151431],\n",
       "        [    88980,     99510,    110040, ...,    141630,    152160,\n",
       "            162690],\n",
       "        [    95136,    106395,    117654, ...,    151431,    162690,\n",
       "            173949]],\n",
       "\n",
       "       [[   197196,    209184,    221172, ...,    257136,    269124,\n",
       "            281112],\n",
       "        [   209184,    221901,    234618, ...,    272769,    285486,\n",
       "            298203],\n",
       "        [   221172,    234618,    248064, ...,    288402,    301848,\n",
       "            315294],\n",
       "        ...,\n",
       "        [   257136,    272769,    288402, ...,    335301,    350934,\n",
       "            366567],\n",
       "        [   269124,    285486,    301848, ...,    350934,    367296,\n",
       "            383658],\n",
       "        [   281112,    298203,    315294, ...,    366567,    383658,\n",
       "            400749]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[173923404, 174279480, 174635556, ..., 175703784, 176059860,\n",
       "         176415936],\n",
       "        [174279480, 174636285, 174993090, ..., 176063505, 176420310,\n",
       "         176777115],\n",
       "        [174635556, 174993090, 175350624, ..., 176423226, 176780760,\n",
       "         177138294],\n",
       "        ...,\n",
       "        [175703784, 176063505, 176423226, ..., 177502389, 177862110,\n",
       "         178221831],\n",
       "        [176059860, 176420310, 176780760, ..., 177862110, 178222560,\n",
       "         178583010],\n",
       "        [176415936, 176777115, 177138294, ..., 178221831, 178583010,\n",
       "         178944189]],\n",
       "\n",
       "       [[179667276, 180029184, 180391092, ..., 181476816, 181838724,\n",
       "         182200632],\n",
       "        [180029184, 180391821, 180754458, ..., 181842369, 182205006,\n",
       "         182567643],\n",
       "        [180391092, 180754458, 181117824, ..., 182207922, 182571288,\n",
       "         182934654],\n",
       "        ...,\n",
       "        [181476816, 181842369, 182207922, ..., 183304581, 183670134,\n",
       "         184035687],\n",
       "        [181838724, 182205006, 182571288, ..., 183670134, 184036416,\n",
       "         184402698],\n",
       "        [182200632, 182567643, 182934654, ..., 184035687, 184402698,\n",
       "         184769709]],\n",
       "\n",
       "       [[185504460, 185872200, 186239940, ..., 187343160, 187710900,\n",
       "         188078640],\n",
       "        [185872200, 186240669, 186609138, ..., 187714545, 188083014,\n",
       "         188451483],\n",
       "        [186239940, 186609138, 186978336, ..., 188085930, 188455128,\n",
       "         188824326],\n",
       "        ...,\n",
       "        [187343160, 187714545, 188085930, ..., 189200085, 189571470,\n",
       "         189942855],\n",
       "        [187710900, 188083014, 188455128, ..., 189571470, 189943584,\n",
       "         190315698],\n",
       "        [188078640, 188451483, 188824326, ..., 189942855, 190315698,\n",
       "         190688541]]])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(x,x,transpose_b=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eea65e0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0,    1,    2, ...,  509,  510,  511],\n",
       "        [1536, 1537, 1538, ..., 2045, 2046, 2047]],\n",
       "\n",
       "       [[ 512,  513,  514, ..., 1021, 1022, 1023],\n",
       "        [2048, 2049, 2050, ..., 2557, 2558, 2559]],\n",
       "\n",
       "       [[1024, 1025, 1026, ..., 1533, 1534, 1535],\n",
       "        [2560, 2561, 2562, ..., 3069, 3070, 3071]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(np.arange(512*3*2).reshape(2,3,512),axes=[1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f303d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[   0,    1,    2, ...,  509,  510,  511],\n",
       "        [ 512,  513,  514, ..., 1021, 1022, 1023],\n",
       "        [1024, 1025, 1026, ..., 1533, 1534, 1535]],\n",
       "\n",
       "       [[1536, 1537, 1538, ..., 2045, 2046, 2047],\n",
       "        [2048, 2049, 2050, ..., 2557, 2558, 2559],\n",
       "        [2560, 2561, 2562, ..., 3069, 3070, 3071]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(512*3*2).reshape(2,3,512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "deba6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def self_attention(q,k,v,depth,mask=None):\n",
    "    scaled_attention = tf.matmul(q,k,transpose_b=True)/tf.math.sqrt(tf.cast(depth,tf.float32))\n",
    "    if mask is not None:\n",
    "        scaled_attention = scaled_attention + mask*(-1e9)\n",
    "    \n",
    "    attentions_wts = tf.nn.softmax(scaled_attention,axis=-1)\n",
    "    weighted_values = tf.matmul(attentions_wts,v)\n",
    "    return attentions_wts,weighted_values\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "096aa586",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model,num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.wq = tf.keras.layers.Dense(d_model) #d_model  = typically 512\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        self.num_heads = num_heads\n",
    "        self.depth = d_model//num_heads\n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        self.d_model = d_model\n",
    "        \n",
    "    def split_heads(self,token_batch):\n",
    "        self.batch_size = tf.shape(token_batch)[0]\n",
    "        seq_len = tf.shape(token_batch)[1]\n",
    "        resized_token_batch = tf.reshape(token_batch,[self.batch_size,seq_len,self.num_heads,self.depth])\n",
    "        resized_token_batch_t=tf.transpose(resized_token_batch,perm=[0,2,1,3])\n",
    "        return resized_token_batch_t\n",
    "    def call(self,q,k,v,mask=None):\n",
    "        q=self.wq(q)\n",
    "        k=self.wk(k)\n",
    "        v=self.wv(v)\n",
    "        \n",
    "        q = self.split_heads(q)\n",
    "        k = self.split_heads(k)\n",
    "        v = self.split_heads(v)\n",
    "        \n",
    "        attentions_wts,weighted_values = self_attention(q,k,v,self.depth,mask)\n",
    "        concatenated_attention = tf.reshape(weighted_values,[self.batch_size,-1,self.d_model])\n",
    "        output = self.dense(concatenated_attention)\n",
    "        return output,attentions_wts\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "584a9170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0., 1., 0., 0.]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[10.,  0.]], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_k = tf.constant([[10, 0, 0],\n",
    "                      [0, 10, 0],\n",
    "                      [0, 0, 10],\n",
    "                      [0, 0, 10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[1, 0],\n",
    "                      [10, 0],\n",
    "                      [100, 5],\n",
    "                      [1000, 6]], dtype=tf.float32)  # (4, 2)\n",
    "\n",
    "# This `query` aligns with the second `key`,\n",
    "# so the second `value` is returned.\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "self_attention(temp_q,temp_k,temp_v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29a4e4e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 4), dtype=float32, numpy=array([[0. , 0. , 0.5, 0.5]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[550. ,   5.5]], dtype=float32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32)  # (1, 3)\n",
    "self_attention(temp_q,temp_k,temp_v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af3e1062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       " array([[0. , 0. , 0.5, 0.5],\n",
       "        [0. , 1. , 0. , 0. ],\n",
       "        [0.5, 0.5, 0. , 0. ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       " array([[550. ,   5.5],\n",
       "        [ 10. ,   0. ],\n",
       "        [  5.5,   0. ]], dtype=float32)>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_q = tf.constant([[0, 0, 10],\n",
    "                      [0, 10, 0],\n",
    "                      [10, 10, 0]], dtype=tf.float32)  # (3, 3)\n",
    "self_attention(temp_q,temp_k,temp_v,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0ae29cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(3)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7896f66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "  angle_rates = 1 / np.power(10000, (2 * (i//2)) / np.float32(d_model))\n",
    "  return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model):\n",
    "  angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "#   print(angle_rads)\n",
    "  # apply sin to even indices in the array; 2i\n",
    "  angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "  # apply cos to odd indices in the array; 2i+1\n",
    "  angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "  pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "  return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d3e2b970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2048, 512)\n"
     ]
    }
   ],
   "source": [
    "n, d = 2048, 512\n",
    "pos_encoding = positional_encoding(n, d)\n",
    "print(pos_encoding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8640e3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6acb40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
    "y = tf.random.uniform((1, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
    "out, attn = t_mha(y,y,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1ed403d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape,attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c45f93a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "   return tf.keras.Sequential([tf.keras.layers.Dense(dff,activation='relu'),tf.keras.layers.Dense(d_model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4fc46bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((64, 50, 512))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f588289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer,self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model,num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model,dff)\n",
    "        \n",
    "        self.layerNorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layerNorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self,x,training,mask=None):\n",
    "        attn_output,attn_wts = self.mha(x,x,x,mask)\n",
    "        attn_output = self.dropout1(attn_output,training=training)\n",
    "        out1 = self.layerNorm1(x+attn_output)\n",
    "        \n",
    "        ffn_out = self.ffn(out1)\n",
    "        ffn_out = self.dropout2(ffn_out,training=training)\n",
    "        out2 = self.layerNorm2(out1+ffn_out)\n",
    "        \n",
    "        return out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13c07e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "sample_encoder_layer_output = sample_encoder_layer(\n",
    "    tf.random.uniform((64, 43, 512)), False, None)\n",
    "\n",
    "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "727e937e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[1., 0., 0.],\n",
       "       [1., 1., 0.],\n",
       "       [1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.linalg.band_part(tf.ones((3, 3)), -1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d6130c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0],\n",
       "       [ 4,  0,  0],\n",
       "       [ 7,  8,  0],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f62f9373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0,  0],\n",
       "       [ 4,  5,  0],\n",
       "       [ 7,  8,  9],\n",
       "       [10, 11, 12]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tril([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2cf2895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.triu(np.ones((3,3)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a07dc432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    return tf.convert_to_tensor(np.triu(np.ones((size,size)),1),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "33628292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1, 3))\n",
    "temp = create_look_ahead_mask(x.shape[1])\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3d581429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000001"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4d6dd9f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[9.9951792e-01, 4.8204057e-04, 0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(tf.constant([[0.637,-7,-1e9]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6da9c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer,self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model=d_model,num_heads = num_heads)\n",
    "        self.mha2 = MultiHeadAttention(d_model=d_model,num_heads = num_heads)\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(d_model = d_model,dff=dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self,x,enc_output,training,lookahead_mask,padding_mask):\n",
    "        mha1_output,attn_wts1 = self.mha1(x,x,x,lookahead_mask)\n",
    "        attn1 = self.dropout1(mha1_output,training=training)\n",
    "        out1 = self.layernorm1(x+attn1)\n",
    "        \n",
    "        mha2_output,attn_wts2 = self.mha2(out1,enc_output,enc_output,padding_mask)\n",
    "        attn2 = self.dropout2(mha2_output,training=training)\n",
    "        out2 = self.layernorm2(out1+attn2)\n",
    "        \n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output,training=training)\n",
    "        out3 = self.layernorm3(ffn_output+out2)\n",
    "        \n",
    "        return out3,attn_wts1,attn_wts2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f5f4d62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 50, 512])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(d_model=512, num_heads=8, dff=2048)\n",
    "\n",
    "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7cd036fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_layers,d_model,num_heads,dff,input_vocab_size,rate=0.1):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.dff = dff\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.rate = rate\n",
    "        self.embedding = tf.keras.layers.Embedding(self.input_vocab_size,self.d_model)\n",
    "        self.pos_encoding = positional_encoding(MAX_TOKENS,self.d_model)\n",
    "        self.enc_layers = [EncoderLayer(d_model=d_model,num_heads=num_heads,dff=dff,rate=self.rate) for _ in range(num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(self.rate)\n",
    "        self.num_layers = num_layers\n",
    "    def call(self,x,training,mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x = x+self.pos_encoding[:,:seq_len,:]\n",
    "        x=self.dropout(x,training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x,training,mask)\n",
    "            \n",
    "        return x\n",
    "\n",
    "MAX_ENCODING = 6000\n",
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, input_vocab_size=8500)\n",
    "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a4a3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self,num_layers,d_model,num_heads,dff,target_vocab_size,rate=0.1):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(MAX_TOKENS, d_model)\n",
    "        \n",
    "        self.dec_layers=[DecoderLayer(d_model=d_model, num_heads=num_heads, dff=dff, rate=rate) for _ in range(num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self,x, enc_output, training,look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        attention_wts={}\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x, training=training)\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                                 look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_wts[f'decoder_layer{i+1}_block1'] = block1\n",
    "            attention_wts[f'decoder_layer{i+1}_block2'] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_wts\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d865291f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                         dff=2048, target_vocab_size=8000)\n",
    "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                              enc_output=sample_encoder_output,\n",
    "                              training=False,\n",
    "                              look_ahead_mask=None,\n",
    "                              padding_mask=None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84ce3281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=bool, numpy=\n",
       "array([[ True,  True, False],\n",
       "       [ True, False, False]])>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = tf.constant([[1,2,0],[4,0,0]])\n",
    "tf.math.logical_not(tf.math.equal(real, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cde05ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self,num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "               target_vocab_size, rate=0.1):\n",
    "        super(Transformer,self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder(num_layers,d_model,num_heads,dff,input_vocab_size,rate)\n",
    "        self.decoder = Decoder(num_layers,d_model,num_heads,dff,target_vocab_size,rate)\n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self,inputs,training):\n",
    "        inp,target = inputs\n",
    "        padding_mask,look_ahead_mask = self.create_masks(inp,target)\n",
    "        enc_output = self.encoder(inp,training,padding_mask)\n",
    "        \n",
    "        dec_output,attention_wts = self.decoder(target,enc_output,training,look_ahead_mask,padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output, attention_wts\n",
    "        \n",
    "    def create_masks(self,inp,tar):\n",
    "        padding_mask = create_padding_mask(inp)\n",
    "        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "        \n",
    "        dec_tar_padding_mask = create_padding_mask(tar)\n",
    "        look_ahead_mask = tf.maximum(dec_tar_padding_mask,look_ahead_mask)\n",
    "        return padding_mask,look_ahead_mask\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11248dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "    input_vocab_size=8500, target_vocab_size=8000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer((temp_input, temp_target), training=False)\n",
    "\n",
    "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c0a9acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e08a4c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self,d_model, warmup_steps=4000):\n",
    "        self.d_model = d_model\n",
    "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "        self.warmup_steps = warmup_steps\n",
    "    def __call__(self,step):\n",
    "        arg1 = np.power(step,-0.5)\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "\n",
    "        return np.power(self.d_model,-0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "056781c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98,\n",
    "                                     epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4149e0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\AppData\\Local\\Temp\\ipykernel_9064\\3822200688.py:7: RuntimeWarning: divide by zero encountered in power\n",
      "  arg1 = np.power(step,-0.5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel('Learning Rate')\n",
    "plt.xlabel('Train Step')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f42c8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37c92ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  loss_ = loss_object(real, pred)\n",
    "\n",
    "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "  loss_ *= mask\n",
    "\n",
    "  return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ec172f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_function(real, pred):\n",
    "  accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
    "\n",
    "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "  accuracies = tf.math.logical_and(mask, accuracies)\n",
    "\n",
    "  accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
    "  mask = tf.cast(mask, dtype=tf.float32)\n",
    "  return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ab361364",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "989169cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    dff=dff,\n",
    "    input_vocab_size=tokenizers.pt.get_vocab_size().numpy(),\n",
    "    target_vocab_size=tokenizers.en.get_vocab_size().numpy(),\n",
    "    rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d5fb1705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_func(inp,tar):\n",
    "    tar_input = tar[:,:-1]\n",
    "    tar_real = tar[:,1:]\n",
    "    with tf.GradientTape() as tape:\n",
    "        preds,_ = transformer((inp,tar_input),training=True)\n",
    "        loss = loss_function(tar_real,preds)\n",
    "    gradients = tape.gradient(loss,transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients,transformer.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(accuracy_function(tar_real, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "04888504",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09feff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 8.8861 Accuracy 0.0000\n",
      "Epoch 1 Batch 50 Loss 8.8460 Accuracy 0.0004\n",
      "Epoch 1 Batch 100 Loss 8.7671 Accuracy 0.0147\n",
      "Epoch 1 Batch 150 Loss 8.6477 Accuracy 0.0306\n",
      "Epoch 1 Batch 200 Loss 8.4976 Accuracy 0.0399\n",
      "Epoch 1 Batch 250 Loss 8.3210 Accuracy 0.0460\n",
      "Epoch 1 Batch 300 Loss 8.1261 Accuracy 0.0504\n",
      "Epoch 1 Batch 350 Loss 7.9244 Accuracy 0.0540\n",
      "Epoch 1 Batch 400 Loss 7.7341 Accuracy 0.0606\n",
      "Epoch 1 Batch 450 Loss 7.5643 Accuracy 0.0682\n",
      "Epoch 1 Batch 500 Loss 7.4140 Accuracy 0.0765\n",
      "Epoch 1 Batch 550 Loss 7.2770 Accuracy 0.0845\n",
      "Epoch 1 Batch 600 Loss 7.1499 Accuracy 0.0921\n",
      "Epoch 1 Batch 650 Loss 7.0293 Accuracy 0.1003\n",
      "Epoch 1 Batch 700 Loss 6.9119 Accuracy 0.1091\n",
      "Epoch 1 Batch 750 Loss 6.8007 Accuracy 0.1179\n",
      "Epoch 1 Batch 800 Loss 6.6904 Accuracy 0.1272\n",
      "Epoch 1 Loss 6.6709 Accuracy 0.1290\n",
      "Time taken for 1 epoch: 15844.14 secs\n",
      "\n",
      "Epoch 2 Batch 0 Loss 4.9110 Accuracy 0.2768\n",
      "Epoch 2 Batch 50 Loss 4.7938 Accuracy 0.3049\n",
      "Epoch 2 Batch 100 Loss 4.7174 Accuracy 0.3143\n",
      "Epoch 2 Batch 150 Loss 4.6214 Accuracy 0.3255\n",
      "Epoch 2 Batch 200 Loss 4.5254 Accuracy 0.3376\n",
      "Epoch 2 Batch 250 Loss 4.4326 Accuracy 0.3491\n",
      "Epoch 2 Batch 300 Loss 4.3244 Accuracy 0.3633\n",
      "Epoch 2 Batch 350 Loss 4.2254 Accuracy 0.3771\n",
      "Epoch 2 Batch 400 Loss 4.1270 Accuracy 0.3911\n",
      "Epoch 2 Batch 450 Loss 4.0315 Accuracy 0.4049\n",
      "Epoch 2 Batch 500 Loss 3.9404 Accuracy 0.4181\n",
      "Epoch 2 Batch 550 Loss 3.8521 Accuracy 0.4304\n",
      "Epoch 2 Batch 600 Loss 3.7638 Accuracy 0.4430\n",
      "Epoch 2 Batch 650 Loss 3.6827 Accuracy 0.4543\n",
      "Epoch 2 Batch 700 Loss 3.6011 Accuracy 0.4657\n",
      "Epoch 2 Batch 750 Loss 3.5192 Accuracy 0.4773\n",
      "Epoch 2 Batch 800 Loss 3.4444 Accuracy 0.4880\n",
      "Epoch 2 Loss 3.4304 Accuracy 0.4900\n",
      "Time taken for 1 epoch: 3821.39 secs\n",
      "\n",
      "Epoch 3 Batch 0 Loss 2.3339 Accuracy 0.6502\n",
      "Epoch 3 Batch 50 Loss 2.1698 Accuracy 0.6672\n",
      "Epoch 3 Batch 100 Loss 2.1918 Accuracy 0.6642\n",
      "Epoch 3 Batch 150 Loss 2.1190 Accuracy 0.6757\n",
      "Epoch 3 Batch 200 Loss 2.0783 Accuracy 0.6820\n",
      "Epoch 3 Batch 250 Loss 2.0466 Accuracy 0.6873\n",
      "Epoch 3 Batch 300 Loss 1.9991 Accuracy 0.6947\n",
      "Epoch 3 Batch 350 Loss 1.9628 Accuracy 0.7001\n",
      "Epoch 3 Batch 400 Loss 1.9253 Accuracy 0.7057\n",
      "Epoch 3 Batch 450 Loss 1.8881 Accuracy 0.7115\n",
      "Epoch 3 Batch 500 Loss 1.8564 Accuracy 0.7163\n",
      "Epoch 3 Batch 550 Loss 1.8327 Accuracy 0.7198\n",
      "Epoch 3 Batch 600 Loss 1.8019 Accuracy 0.7243\n",
      "Epoch 3 Batch 650 Loss 1.7757 Accuracy 0.7283\n",
      "Epoch 3 Batch 700 Loss 1.7535 Accuracy 0.7317\n",
      "Epoch 3 Batch 750 Loss 1.7320 Accuracy 0.7348\n",
      "Epoch 3 Batch 800 Loss 1.7073 Accuracy 0.7383\n",
      "Epoch 3 Loss 1.7042 Accuracy 0.7387\n",
      "Time taken for 1 epoch: 3810.70 secs\n",
      "\n",
      "Epoch 4 Batch 0 Loss 1.3774 Accuracy 0.7843\n",
      "Epoch 4 Batch 50 Loss 1.2913 Accuracy 0.7990\n",
      "Epoch 4 Batch 100 Loss 1.3026 Accuracy 0.7981\n",
      "Epoch 4 Batch 150 Loss 1.2961 Accuracy 0.7992\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "  start = time.time()\n",
    "\n",
    "  train_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "\n",
    "  # inp -> portuguese, tar -> english\n",
    "  for (batch, (inp, tar)) in enumerate(train_batches):\n",
    "    training_func(inp, tar)\n",
    "\n",
    "    if batch % 50 == 0:\n",
    "      print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  if (epoch + 1) % 5 == 0:\n",
    "    ckpt_save_path = ckpt_manager.save()\n",
    "    print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
    "\n",
    "  print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
    "\n",
    "  print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed38e66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
